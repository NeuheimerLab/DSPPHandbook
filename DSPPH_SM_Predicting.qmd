---
title: "Statistical Modelling: Predicting"
bibliography: handbook.bib

number-sections: true
number-depth: 2

---


```{r} 
#| echo: false
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```


```{r}
#| echo: false
library(png)
library(grid)
library(formatR)
library(dplyr)
```

::: {.callout-tip collapse="false"} 
## In this chapter you will learn:

- how to use your statistical model to make a prediction

:::

# Predicting

One of the motivations we discussed [motivations for statistical modelling](handbookSMIntro.qmd) was that models help us to make quantitative predictions about the system which we are studying.^[In a previous section, we had the quote "All models are wrong but some are useful" to emphasize that models are approximation of the real world.  Well, we can also say that "all data are wrong, but models can make data useful" (a quote by Andy Pershing) to emphasize that models are also needed to make generalizations and predictions about the systems that we are studying.]


Now that you have your best-specified model, you may want to use it to make a response prediction^[I realize that the term "prediction" and "predictor" can be confusing.  Remember that another word for your model predictor is "covariate".], e.g. "what would I expect the value of my response to be at a different value of my predictor?" 



::: {.alert .alert-warning}

The predicting process outlined here is similar regardless of your model structure (e.g. error distribution assumption).  You can use the same process for models of any structure.

:::

## The process

Here we will go through the steps involved in using your model to make a prediction about your response, including (most importantly):

### Step Zero: consider your prediction limits {.unnumbered}

Before using your model to make a prediction, ask yourself: is it even logical to make this prediction?

Things you should consider:

* **do I have a numeric predictor in my best-specified model?**

If you have only categorical predictors in your model, you can not use your model to make a prediction outside the categories already in your model.

Let's bring in our Example 1 from the last chapter on Reporting to illustrate the prediction limits of models with only categorical predictors:

`Resp1 ~ Cat1`


```{r echo = FALSE}

library(dplyr)

# Example 1: Resp1 ~ Cat1
 n=100
 ss<-sample(c(1:1000), 1)
 set.seed(679) #582
Cat1<-as.factor(sample(c("G", "K", "R"), size=n, replace=TRUE))

Group <- as.factor(sample(c("Site1", "Site2", "Site3", "Site4", "Site5", "Site6"),
                           n, replace=TRUE))
uResp<-(as.numeric(Cat1)*4.4+3.9*as.numeric(Group))#+sample(c(200:900), n, replace = TRUE)
Resp<-rnorm(n, uResp, 4.5)
Group <- recode(Group,
                    Site1 = 'Site3',
                    Site2 = 'Site1',
                    Site3 = 'Site5',
                   Site4 = 'Site4',
                   Site5 = 'Site2',
                   Site6 = 'Site6')
Group <- factor(Group, levels = c("Site1","Site2","Site3","Site4","Site5","Site6"))
Cat1 <- recode(Cat1,
                    K = 'Sp1',
                    R = 'Sp2',
                    G = 'Sp3')
Cat1<-factor(Cat1, levels = c("Sp1", "Sp2", "Sp3"))
myDat1<-data.frame(Cat1=Cat1, Resp1=round(Resp,1))
# #write.csv(myDat, "DatEx1.csv", row.names = FALSE)
# 
# library(ggplot2)
# ggplot()+
#   geom_point(data=myDat,
#              mapping=aes(x=Cat1, y=Resp1))
#
startMod<-glm(formula = Resp1 ~ Cat1 + 1, # hypothesis
              data = myDat1, # data
              family = gaussian(link="identity")) # error distribution assumption
# 
# 
# 
library(DHARMa)
# simulationOutput <- simulateResiduals(fittedModel = startMod, n = 250) # simulate data from our model n times
# #
# plot(simulationOutput, asFactor=TRUE) # compare simulated data to our observations
# #
# plot(simulationOutput,
#      form=myDat1$Cat1,
#      asFactor=TRUE) # compare simulated data to our observations
# # #
# myDat$Resid<-simulationOutput$scaledResiduals
# # # # 
# 
# # #
# ggplot()+
#   geom_violin(data=myDat,
#              mapping = aes(x=Group, y=Resid))
# 
# #
# #
library(MuMIn)
options(na.action = "na.fail") # needed for dredge() function to prevent illegal model comparisons
dredgeOut<-dredge(startMod) # fit and compare a model set representing all possible predictor combinations
#
bestMod<-(eval(attr(dredgeOut, "model.calls")$`2`)) # extract model #8 from dredge table
#
# #
# library(emmeans)
# forComp <- emmeans(bestMod, specs =  ~ Cat1, type = "response")
# forComp
# plot(forComp)
# plot(forComp, comparisons = TRUE)
# plot(pairs(emmeans(bestMod, "Cat1"),
#               adjust="scheffe"))

dredgeOut1<-dredgeOut
bestMod1<-bestMod

# Set up your predictors for the visualized fit
forCat1<-unique(myDat1$Cat1) # every value of your categorical predictor

# create a data frame with your predictors
forVis<-expand.grid(Cat1=forCat1) # expand.grid() function makes sure you have all combinations of predictors



# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod1, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod1)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame

library(ggplot2)

ggplot() + # start ggplot
  geom_point(data = myDat1, # add observations to your plot
             mapping = aes(x = Cat1, y = Resp1), 
             position=position_jitter(width=0.1)) + # control position of data points so they are easier to see on the plot
  geom_errorbar(data = forVis, # add the uncertainty to your plot
              mapping = aes(x = Cat1, y = Fit, ymin = Lower, ymax = Upper),
              linewidth=1.2) + # control thickness of errorbar line
  geom_point(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cat1, y = Fit), 
             shape = 22, # shape of point
             size = 3, # size of point
             fill = "white", # fill colour for plot
             col = 'black') + # outline colour for plot
  ylab("Resp1, (units)")+ # change y-axis label
  xlab("Cat1, (units)")+ # change x-axis label
  theme_bw() # change ggplot theme

```
Here you can see the modelled `Resp1` when `Cat1` is Sp1, Sp2 or Sp3.  You are not able to make a prediction for `Cat1 = Sp4` or `Cat1 = Sp63`.  This is limits of prediction limit when you have a categorical predictor.  You are able to report the variability in `Resp1` that is explained by `Cat1` - this can give you an idea for how much `Resp1` might vary if you study a new species.

* **Can I assume that my model assumptions will hold under my prediction conditions?**

By using your model to make a prediction, you are assuming that the same processes that govern the relationship(s) between your predictor(s) and response will hold at the new value of your predictor. 
For example, you might have used a linear shape assumption that was appropriate for modelling how growth varies due to temperature for your data, but now you want to estimate growth at an even higher temperature than you tested.  Is this appropriate?  Would it be possible that temperature has exceeded a tolerance limit and that growth starts to respond non-linearly with temperature? 


<img src="./predLimitsTPC.png" width="700px"/>



As you can see, you need to consider prediction limits particularly when you are making a prediction using a value of your predictor *outside* the range of your predictor used to fit your model.

You also need to consider prediction limits when you are wanting to predict your response at a future time or different location.

In all cases: Think about the mechanisms underlying your hypothesis to consider if they are likely to be the same under your prediction conditions.  This will help you decide if making a prediction is appropriate.

### Step One: Define the predictor values for your response prediction {.unnumbered}

The first step in using your model to make a response prediction is to define the values of your predictor(s) at which you want to make the response prediction.  Note that you need to define a value for *each* of the predictors in your model, the defined values need to be in a data frame, and the columns should be given the same names as your predictors.  

### Step Two: Make your response prediction {.unnumbered}

You can use the `predict()`^[note that when you hand a GLM object to `predict()`, R actually uses a function called `predict.glm()`.  This does not affect what you need to do; it is just good to know in case you need help with the function] function to predict the value of your response.

## Examples 

Note that Example 1 (`Resp1 ~ Cat1`) and Example 2 (`Resp2 ~ Cat2 + Cat3 + Cat2:Cat3 + 1`) from the previous chapter on Reporting only contained categorical predictors, so we will not explore them further here.

Examples 3 (`Resp3 ~ Cont4 + 1`) and 4 (`Resp4 ~ Cat5 + Cont6 + Cat5:Cont6 + 1`) each contain a numeric predictor, so we will use those here as an example of how to use your models to make a prediction of your response.

### Example 3: Resp3 ~ Cont4 + 1 {.unnumbered}

Here's a reminder of Example 3 (`Resp3 ~ Cont4 + 1`): 

```{r echo = FALSE}

#rm(list=ls())
n=100
ss<-sample(c(1:1000), 1)
set.seed(261) #261
Cont4<-round(runif(n, 0.3, 20.9),2)
uResp<-245*Cont4+ 10
Resp<-rnorm(n, uResp, 850)
myDat3<-data.frame(Resp3=Resp, Cont4=Cont4)

# # #write.csv(myDat3, "DatEx3.csv", row.names = FALSE)


# ggplot()+
#   geom_point(data=myDat3,
#              mapping=aes(x=Cont4, y=Resp3))

startMod<-glm(formula = Resp3 ~ Cont4 + 1, # hypothesis
              data = myDat3, # data
              family = gaussian(link="identity")) # error distribution assumption


# # 
# library(DHARMa)
# simulationOutput <- simulateResiduals(fittedModel = startMod, n = 250) # simulate data from our model n times
# #
# plot(simulationOutput, asFactor=TRUE) # compare simulated data to our observations
# #
# plot(simulationOutput,
#      form=myDat3$Cont4,
#      asFactor=FALSE) # compare simulated data to our observations
# 
# #
# #
# #
library(MuMIn)
options(na.action = "na.fail") # needed for dredge() function to prevent illegal model comparisons
dredgeOut<-dredge(startMod) # fit and compare a model set representing all possible predictor combinations
#dredgeOut
#
bestMod<-(eval(attr(dredgeOut, "model.calls")$`2`)) # extract model #8 from dredge table
#
# #
# library(emmeans)
# forComp <- emmeans(bestMod, specs =  ~ Cat1, type = "response")
# forComp
# plot(forComp)
# plot(forComp, comparisons = TRUE)
# plot(pairs(emmeans(bestMod, "Cat1"),
#               adjust="scheffe"))

dredgeOut3<-dredgeOut
bestMod3<-bestMod

#### i) choosing the values of your predictors at which to make a prediction


# Set up your predictors for the visualized fit
forCont4<-seq(from = min(myDat3$Cont4), to = max(myDat3$Cont4), by = 1)# a sequence of numbers in your numeric predictor range
  
# create a data frame with your predictors
forVis<-expand.grid(Cont4 = forCont4) # expand.grid() function makes sure you have all combinations of predictors.  

#### ii) using `predict()` to use your model to estimate your response variable at those values of your predictor


# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod3, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod3)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame


#### iii) use the model estimates to plot your model fit


library(ggplot2) # load ggplot2 library

ggplot() + # start ggplot
  
  geom_point(data = myDat3, # add observations to your plot
             mapping = aes(x = Cont4, y = Resp3)) + # control position of data points so they are easier to see on the plot
  
  geom_line(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cont4, y = Fit),
              linewidth = 1.2) + # control thickness of line
  
    geom_line(data = forVis, # add uncertainty to your plot (upper line)
              mapping = aes(x = Cont4, y = Upper),
              linewidth = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
      geom_line(data = forVis, # add uncertainty to your plot (lower line)
              mapping = aes(x = Cont4, y = Lower),
              linewidth = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
  ylab("Resp3, (units)") + # change y-axis label
  
  xlab("Cont4, (units)") + # change x-axis label
  
  theme_bw() # change ggplot theme



```



#### What is the predicted response of `Resp3` when `Cont4 = 30`?


```{r}

## Step One: Define the predictor values for your response prediction
forPred <- data.frame(Cont4 = 30) # the values of my predictor at which I want a response prediction

## Step Two: Make your response prediction
myPred<-predict(bestMod3, # the model
                newdata = forPred, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod3)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

### This can be added to our forPred data frame as:
forPred$Fit<-ilink(myPred$fit) # add your fit to the data frame
forPred$Lower<-ilink(myPred$fit - 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forPred$Upper<-ilink(myPred$fit + 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals


forPred
     
```
Note that you get the response prediction in `forPred$Fit` = `r round(forPred$Fit)` units and an estimate of uncertainty around this prediction as the 95% confidence intervals (`r round(forPred$Lower)` to `r round(forPred$Upper)` units).

Note that you can also use the [ggeffects package](https://strengejacke.github.io/ggeffects/) to make these predictions.

So the value of `Resp3` when `Cont4 = 30 units` is `r round(forPred$Fit)` units (95% confidence intervals: `r round(forPred$Lower)` to `r round(forPred$Upper)` units).

You can add this to your plot with:

```{r}

# Set up your predictors for the visualized fit
forCont4<-seq(from = min(myDat3$Cont4), to = max(myDat3$Cont4), by = 1)# a sequence of numbers in your numeric predictor range
  
# create a data frame with your predictors
forVis<-expand.grid(Cont4 = forCont4) # expand.grid() function makes sure you have all combinations of predictors.  

# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod3, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod3)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame


library(ggplot2) # load ggplot2 library

ggplot() + # start ggplot
  
  geom_point(data = myDat3, # add observations to your plot
             mapping = aes(x = Cont4, y = Resp3)) + # control position of data points so they are easier to see on the plot
  
  geom_line(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cont4, y = Fit),
              size = 1.2) + # control thickness of line
  
    geom_line(data = forVis, # add uncertainty to your plot (upper line)
              mapping = aes(x = Cont4, y = Upper),
              size = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
      geom_line(data = forVis, # add uncertainty to your plot (lower line)
              mapping = aes(x = Cont4, y = Lower),
              size = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
  ### NEW!  Adding your response prediction to the plot:
  geom_point(data = forPred, # prediction data frame
             mapping = aes(x = Cont4, y = Fit), # coordinates of prediction
             col = "red", # change point colour
             size = 3) + # change point size
  
  ### NEW!  Adding errorbars for your response prediction to the plot:
  geom_errorbar(data = forPred, # prediction data frame
             mapping = aes(x = Cont4, ymax = Upper, ymin = Lower), # coordinates of prediction
             width = 1, # the width of the error bars
             col = "red") + # change point colour
  
  
  ylab("Resp3, (units)") + # change y-axis label
  
  xlab("Cont4, (units)") + # change x-axis label
  
  theme_bw() # change ggplot theme



```


#### What are the predicted responses of `Resp3` when `Cont4 = 9` and `Cont4 = 22`?

```{r}

## Step One: Define the predictor values for your response prediction
forPred <- data.frame(Cont4 = c(9,22)) # the values of my predictor at which I want a response prediction

## Step Two: Make your response prediction
myPred<-predict(bestMod3, # the model
                newdata = forPred, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod3)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

### This can be added to our forPred data frame as:
forPred$Fit<-ilink(myPred$fit) # add your fit to the data frame
forPred$Lower<-ilink(myPred$fit - 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forPred$Upper<-ilink(myPred$fit + 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals


forPred
     
```
Note that you now get two predictions, one for `Cont4 = 9` and one for `Cont4 = 22`:

* The value of `Resp3` when `Cont4 = 9 units` is `r round(forPred$Fit[1])` units (95% confidence intervals: `r round(forPred$Lower[1])` to `r round(forPred$Upper[1])` units).

* The value of `Resp3` when `Cont4 = 22 units` is `r round(forPred$Fit[2])` units (95% confidence intervals: `r round(forPred$Lower[2])` to `r round(forPred$Upper[2])` units).

You can add this to your plot with:

```{r}

# Set up your predictors for the visualized fit
forCont4<-seq(from = min(myDat3$Cont4), to = max(myDat3$Cont4), by = 1)# a sequence of numbers in your numeric predictor range
  
# create a data frame with your predictors
forVis<-expand.grid(Cont4 = forCont4) # expand.grid() function makes sure you have all combinations of predictors.  

# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod3, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod3)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame


library(ggplot2) # load ggplot2 library

ggplot() + # start ggplot
  
  geom_point(data = myDat3, # add observations to your plot
             mapping = aes(x = Cont4, y = Resp3)) + # control position of data points so they are easier to see on the plot
  
  geom_line(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cont4, y = Fit),
              size = 1.2) + # control thickness of line
  
    geom_line(data = forVis, # add uncertainty to your plot (upper line)
              mapping = aes(x = Cont4, y = Upper),
              size = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
      geom_line(data = forVis, # add uncertainty to your plot (lower line)
              mapping = aes(x = Cont4, y = Lower),
              size = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
  ### NEW!  Adding your response prediction to the plot:
  geom_point(data = forPred, # prediction data frame
             mapping = aes(x = Cont4, y = Fit), # coordinates of prediction
             col = "orange", # change point colour
             size = 3) + # change point size
  
  ### NEW!  Adding errorbars for your response prediction to the plot:
  geom_errorbar(data = forPred, # prediction data frame
             mapping = aes(x = Cont4, ymax = Upper, ymin = Lower), # coordinates of prediction
             width = 1, # the width of the error bars
             col = "orange") + # change point colour
  
  ylab("Resp3, (units)") + # change y-axis label
  
  xlab("Cont4, (units)") + # change x-axis label
  
  theme_bw() # change ggplot theme



```

### Example 4: Resp4 ~ Cat5 + Cont6 + Cat5:Cont6 + 1 {.unnumbered}


Here's a reminder of Example 4 (`Resp4 ~ Cat5 + Cont6 + Cat5:Cont6 + 1`): 

```{r echo = FALSE}

#rm(list=ls())
n=100
ss<-sample(c(1:1000), 1)
set.seed(444) #444
Cat5<-as.factor(sample(c("Wild", "Farm", "Urban"), size=n, replace=TRUE))
Cont6<-round(runif(n, 300, 700),2)
uResp<-(as.numeric(Cat5)*0.014-0.02*Cont6+ as.numeric(Cat5)*0.014*Cont6)+100
Resp<-rnorm(n, uResp, 2.5)
myDat4<-data.frame(Resp4=Resp, Cat5=Cat5, Cont6=Cont6)

# # #write.csv(myDat3, "DatEx3.csv", row.names = FALSE)


# ggplot()+
#   geom_point(data=myDat3,
#              mapping=aes(x=Cont5, y=Resp3, col=Cat4))

startMod<-glm(formula = Resp4 ~ Cat5 + Cont6 + Cat5:Cont6 + 1, # hypothesis
              data = myDat4, # data
              family = gaussian(link="identity")) # error distribution assumption


# 
# library(DHARMa)
# simulationOutput <- simulateResiduals(fittedModel = startMod, n = 250) # simulate data from our model n times
# #
# plot(simulationOutput, asFactor=TRUE) # compare simulated data to our observations
# #
# plot(simulationOutput,
#      form=myDat3$Cat4,
#      asFactor=TRUE) # compare simulated data to our observations
# 
# plot(simulationOutput,
#      form=myDat3$Cont5,
#      asFactor=FALSE) # compare simulated data to our observations

#
#
# #
library(MuMIn)
options(na.action = "na.fail") # needed for dredge() function to prevent illegal model comparisons
dredgeOut<-dredge(startMod, extra = "R^2") # fit and compare a model set representing all possible predictor combinations
#dredgeOut
#
bestMod<-(eval(attr(dredgeOut, "model.calls")$`8`)) # extract model #8 from dredge table
#
# #
# library(emmeans)
# forComp <- emmeans(bestMod, specs =  ~ Cat1, type = "response")
# forComp
# plot(forComp)
# plot(forComp, comparisons = TRUE)
# plot(pairs(emmeans(bestMod, "Cat1"),
#               adjust="scheffe"))

dredgeOut4<-dredgeOut
bestMod4<-bestMod

#### i) choosing the values of your predictors at which to make a prediction


# Set up your predictors for the visualized fit
forCat5<-unique(myDat4$Cat5) # all levels of your categorical predictor
forCont6<-seq(from = min(myDat4$Cont6), to = max(myDat4$Cont6), by = 1)# a sequence of numbers in your numeric predictor range
  
# create a data frame with your predictors
forVis<-expand.grid(Cat5 = Cat5, Cont6 = forCont6) # expand.grid() function makes sure you have all combinations of predictors.  

#### ii) using `predict()` to use your model to estimate your response variable at those values of your predictor


# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod4, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod4)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame


#### iii) use the model estimates to plot your model fit


library(ggplot2) # load ggplot2 library

ggplot() + # start ggplot
  
  geom_point(data = myDat4, # add observations to your plot
             mapping = aes(x = Cont6, y = Resp4, col = Cat5)) + # control position of data points so they are easier to see on the plot
  
  geom_line(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cont6, y = Fit, col = Cat5),
              size = 1.2) + # control thickness of line
  
    geom_line(data = forVis, # add uncertainty to your plot (upper line)
              mapping = aes(x = Cont6, y = Upper, col = Cat5),
              size = 0.4, # control thickness of line
              linetype = 2) + # control style of line
  
      geom_line(data = forVis, # add uncertainty to your plot (lower line)
              mapping = aes(x = Cont6, y = Lower, col = Cat5),
              size = 0.4, # control thickness of line
              linetype = 2) + # control style of line
  
  ylab("Resp4, (units)") + # change y-axis label
  
  xlab("Cont6, (units)") + # change x-axis label
  
  labs(fill="Cat5, (units)", col="Cat5, (units)") + # change legend title
  
  theme_bw() # change ggplot theme



```


#### Example: What is the predicted response of `Resp4` when `Cont6 = 800` for `Cat5 = Urban`?


```{r}

## Step One: Define the predictor values for your response prediction
forPred <- data.frame(Cont6 = 800,
                      Cat5 = "Urban") # the values of my predictor at which I want a response prediction

## Step Two: Make your response prediction
myPred<-predict(bestMod4, # the model
                newdata = forPred, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod4)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

### This can be added to our forPred data frame as:
forPred$Fit<-ilink(myPred$fit) # add your fit to the data frame
forPred$Lower<-ilink(myPred$fit - 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forPred$Upper<-ilink(myPred$fit + 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals


forPred
     
```

So the value of `Resp4` when `Cont6 = 800` units for `Cat5 = Urban` is `r round(forPred$Fit,1)` units (95% confidence intervals: `r round(forPred$Lower,1)` to `r round(forPred$Upper,1)` units).

You can add this to your plot with:

```{r}

#### i) choosing the values of your predictors at which to make a prediction
# Set up your predictors for the visualized fit
forCat5<-unique(myDat4$Cat5) # all levels of your categorical predictor
forCont6<-seq(from = min(myDat4$Cont6), to = max(myDat4$Cont6), by = 1)# a sequence of numbers in your numeric predictor range
  
# create a data frame with your predictors
forVis<-expand.grid(Cat5 = Cat5, Cont6 = forCont6) # expand.grid() function makes sure you have all combinations of predictors.  

#### ii) using `predict()` to use your model to estimate your response variable at those values of your predictor


# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod4, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod4)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame


#### iii) use the model estimates to plot your model fit


library(ggplot2) # load ggplot2 library

ggplot() + # start ggplot
  
  geom_point(data = myDat4, # add observations to your plot
             mapping = aes(x = Cont6, y = Resp4, col = Cat5)) + # control position of data points so they are easier to see on the plot
  
  geom_line(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cont6, y = Fit, col = Cat5),
              size = 1.2) + # control thickness of line
  
    geom_line(data = forVis, # add uncertainty to your plot (upper line)
              mapping = aes(x = Cont6, y = Upper, col = Cat5),
              size = 0.4, # control thickness of line
              linetype = 2) + # control style of line
  
      geom_line(data = forVis, # add uncertainty to your plot (lower line)
              mapping = aes(x = Cont6, y = Lower, col = Cat5),
              size = 0.4, # control thickness of line
              linetype = 2) + # control style of line
  
  
    ### NEW!  Adding your response prediction to the plot:
  geom_point(data = forPred, # prediction data frame
             mapping = aes(x = Cont6, y = Fit, col = Cat5), # coordinates of prediction
             #col = "black", # change point colour
             size = 3) + # change point size
  
  ### NEW!  Adding errorbars for your response prediction to the plot:
  geom_errorbar(data = forPred, # prediction data frame
             mapping = aes(x = Cont6, ymax = Upper, ymin = Lower,  col = Cat5), # coordinates of prediction
             width = 20, # the width of the error bars
             #col = "black"
             ) + # change point colour
  
  ylab("Resp4, (units)") + # change y-axis label
  
  xlab("Cont6, (units)") + # change x-axis label
  
  labs(fill="Cat5, (units)", col="Cat5, (units)") + # change legend title
  
  theme_bw() # change ggplot theme





```

#### Example: What is the predicted response of `Resp4` when `Cont6 = 800` for both `Cat5 = Urban` and `Cat5 = Wild`?

Note the extra step with `expand.grid()` that allows you to quickly set up your predictor values for the prediction.

```{r}

## Step One: Define the predictor values for your response prediction
forCat5 <- c("Urban", "Wild") # values of Cat5 for predictions
forCont6 <- 800 # value of Cont6 for prediction

forPred <- expand.grid(Cat5 = forCat5, Cont6 = forCont6) # expand.grid() function makes sure you have all combinations of predictors.

## Step Two: Make your response prediction
myPred<-predict(bestMod4, # the model
                newdata = forPred, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod4)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

### This can be added to our forPred data frame as:
forPred$Fit<-ilink(myPred$fit) # add your fit to the data frame
forPred$Lower<-ilink(myPred$fit - 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forPred$Upper<-ilink(myPred$fit + 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals


forPred
     
```

So

* the value of `Resp4` when `Cont6 = 800` units is  both `Cat5 = Urban` is `r round(forPred$Fit[1],1)` units (95% confidence intervals: `r round(forPred$Lower[1],1)` to `r round(forPred$Upper[1],1)` units).

* the value of `Resp4` when `Cont6 = 800` units is  both `Cat5 = Wild` is `r round(forPred$Fit[2],1)` units (95% confidence intervals: `r round(forPred$Lower[2],1)` to `r round(forPred$Upper[2],1)` units).

You can add this to your plot with:

```{r}

#### i) choosing the values of your predictors at which to make a prediction
# Set up your predictors for the visualized fit
forCat5<-unique(myDat4$Cat5) # all levels of your categorical predictor
forCont6<-seq(from = min(myDat4$Cont6), to = max(myDat4$Cont6), by = 1)# a sequence of numbers in your numeric predictor range
  
# create a data frame with your predictors
forVis<-expand.grid(Cat5 = forCat5, Cont6 = forCont6) # expand.grid() function makes sure you have all combinations of predictors.  

#### ii) using `predict()` to use your model to estimate your response variable at those values of your predictor


# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod4, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod4)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame


#### iii) use the model estimates to plot your model fit


library(ggplot2) # load ggplot2 library

ggplot() + # start ggplot
  
  geom_point(data = myDat4, # add observations to your plot
             mapping = aes(x = Cont6, y = Resp4, col = Cat5)) + # control position of data points so they are easier to see on the plot
  
  geom_line(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cont6, y = Fit, col = Cat5),
              size = 1.2) + # control thickness of line
  
    geom_line(data = forVis, # add uncertainty to your plot (upper line)
              mapping = aes(x = Cont6, y = Upper, col = Cat5),
              size = 0.4, # control thickness of line
              linetype = 2) + # control style of line
  
      geom_line(data = forVis, # add uncertainty to your plot (lower line)
              mapping = aes(x = Cont6, y = Lower, col = Cat5),
              size = 0.4, # control thickness of line
              linetype = 2) + # control style of line
  
  
    ### NEW!  Adding your response prediction to the plot:
  geom_point(data = forPred, # prediction data frame
             mapping = aes(x = Cont6, y = Fit, col = Cat5), # coordinates of prediction
             #col = "black", # change point colour
             size = 3) + # change point size
  
  ### NEW!  Adding errorbars for your response prediction to the plot:
  geom_errorbar(data = forPred, # prediction data frame
             mapping = aes(x = Cont6, ymax = Upper, ymin = Lower,  col = Cat5), # coordinates of prediction
             width = 20, # the width of the error bars
             #col = "black"
             ) + # change point colour
  
  ylab("Resp4, (units)") + # change y-axis label
  
  xlab("Cont6, (units)") + # change x-axis label
  
  labs(fill="Cat5, (units)", col="Cat5, (units)") + # change legend title
  
  theme_bw() # change ggplot theme





```
## Inverse predicting for models with a binomial error distribution assumption

While the process (and code) above is *identical* regardless of your error distribution assumption, there is a second type of predicting one often uses when one has a model with a binomial error distribution assumption^[recall that this is also called "logistic regression"].  

Here, you are "inverse predicting" to predict the value of your *predictor* that will lead to a certain probability of your response being 1.

For example, you might want to know the amount of a toxin (your predictor) that leads to a 25% probability of dying^[sometimes called $LD_{25}$ where LD is lethal dose], or the age (your predictor) at which a fish has a 50% probability of being mature^[sometimes called the $A_{50}$].


```{r echo = FALSE}

n = 300 # sample size

## Prep data
### random number generator tracking
ss<-sample(c(1:1000), 1) # for setting random number generating
set.seed(100) # for setting random number generating, 308

### Prep predictor(s)
Cont1 <- runif(n, min = 30, max = 120)

forNoise <-1  # change to vary noise (actually controls effect, not noise)
forSlope2 <- runif(1, min = 0.1, max = 0.14) # effect size as change categorical levels (or slope)
forInt <- runif(1, min = 0.001, max = 0.004) # intercept
xbeta <- ((Cont1*forSlope2) + forInt)^(1/forNoise)
xbeta <-xbeta - mean(xbeta)
pr <- 1/(1+exp(-xbeta)) # or plogis(xbeta)?
#### response data
Resp<- rbinom(length(pr), 1, pr)


## make data frame
myDat3.b<-data.frame(Cont4 = Cont1, Resp3.b=Resp)


## get best-specified model - normal:
startMod3.b<-glm(formula = Resp3.b ~ Cont4 + 1, # hypothesis
               data = myDat3.b, # data
               family = binomial(link="logit")) # error distribution assumption

simulationOutput <- simulateResiduals(fittedModel = startMod, n = 250) # simulate data from our model n times
# 
# plotQQunif(simulationOutput, # the object made when estimating the scaled residuals.  See section 2.1 above
#            testUniformity = TRUE, # testing the distribution of the residuals 
#            testOutliers = TRUE, # testing the presence of outliers
#            testDispersion = TRUE) # testing the dispersion of the distribution
# 
# plotResiduals(simulationOutput, # the object made when estimating the scaled residuals.  See section 2.1 above
#               form = NULL) # the variable against which to plot the residuals.  When form = NULL, we see the residuals vs. fitted values
#               
#            
# plotResiduals(simulationOutput, # the object made when estimating the scaled residuals.  See section 2.1 above
#               form = myDat3.b$Cont1) # the variable against which to plot the residuals.  When form = NULL, we see the residuals vs. fitted values
#                  

options(na.action = "na.fail") # needed for dredge() function to prevent illegal model comparisons

dredgeOut<-dredge(startMod3.b, extra = "R^2") # fit and compare a model set representing all possible predictor combinations

bestMod<-(eval(attr(dredgeOut, "model.calls")$`2`))




dredgeOut3.b<-dredgeOut
bestMod3.b<-bestMod

```


One method to do this would be to predict your response at values of your predictor in high enough resolution so that you can pick out the appropriate predictor value.  Here is an example where you want to know the value of `Cont4` that will give a 75% probability of `Resp3.b` being 1, given your bestmod3.b of `Resp3.b ~ Cont4 + 1`:

```{r}

forCont4<-seq(from = min(myDat3.b$Cont4), to = max(myDat3.b$Cont4), by = 0.01)# a sequence of numbers in your numeric predictor range, notice that you are using a very high resolution series of your predictor here.

forPred <- expand.grid(Cont4 = forCont4) # expand.grid() function makes sure you have all combinations of predictors.


## Step Two: Make your response prediction
myPred<-predict(bestMod3.b, # the model
                newdata = forPred, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod3.b)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

### This can be added to our forPred data frame as:
forPred$Fit<-ilink(myPred$fit) # add your fit to the data frame
forPred$Lower<-ilink(myPred$fit - 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forPred$Upper<-ilink(myPred$fit + 1.96*myPred$se.fit) # add your uncertainty to the data frame, 95% confidence intervals

myPredDF <- data.frame(Cont4 = forCont4,
                       Fit = forPred$Fit,
                       Lower = forPred$Lower,
                       Upper = forPred$Upper)

myPredDF$Diff <- abs(myPred$fit - 0.75)

myInvPred <- myPredDF[which(myPredDF$Diff == min(myPredDF$Diff)),]

myInvPred


```
The estimate of `Cont4` that leads to a 75% probability of `Resp3.b` being 1 is `r round(myInvPred$Fit, 1)` units (95% confidence intervals: `r round(myInvPred$Lower, 2)` to `r round(myInvPred$Upper, 2)`.

As you can see, this is a bit tedious.  Another method would be to make a function yourself based on your statistical model equation and coefficients:

Note that your statistical model (GLM) with a binomial error distribution is:

$$ log_n(\frac{p}{1-p}) = \beta_0 + \beta_1 \cdot x $$

where 
$log_n(\frac{p}{1-p})$ is the logit function of the odds (see the [Reporting](DSPPH_SM_Reporting.qmd) section for more),
$p$ is the probability at which you want a value of your predictor,
$x$ is the value of your predictor,
$\beta_0$ is your modelled intercept, and
$\beta_1$ is your modelled slope (effect of your numeric predictor).

Inverse predicting means finding the value of $x$ that gives you a particular value of $p$.  So we need to solve our equation for $x$:


\begin{align}
log_n(\frac{p}{1-p}) &= \beta_0 + \beta_1 \cdot x\\[1em]

log_n(\frac{p}{1-p}) - \beta_0 &= \beta_1 \cdot x\\[1em]

\frac{log_n(\frac{p}{1-p}) - \beta_0}{\beta_1} &=  x\\[1em]

\end{align}


Then we can solve $x$ for a particular value of $p$.  For example, what value of `Cont4` will give a 75% probability of `Resp3.b` being 1, given your bestmod3.b of `Resp3.b ~ Cont4 + 1`:

```{r}

# Make my inverse predicting function that is specific to this model:
funInvPred <- function (p, model) {
  modLink <- family(model)$linkfun # get the conversion (link) for the model
  (modLink(p) - coef(model)[["(Intercept)"]]) / coef(model)[["Cont4"]] # calculate x from p
}

# Apply the equation to estimate Cont4 when there is a 75% probability of Resp3.b being 1:
myInvPred <- funInvPred(p = 0.75, model = bestMod3.b) 

myInvPred

```

The result is that you will have a 75% probability of `Resp3.b` being 1 if your `Cont4` is r round(myInvPred,1) units.  Note that there is no error estimated here.  Generalized linear models assume that there is no error in your predictors, so getting the error on your inverse prediction is tricky and beyond the scope of this handbook. 

Let's finish here by adding our inverse prediction to the plot:


```{r echo = FALSE}

#### i) choosing the values of your predictors at which to make a prediction


# Set up your predictors for the visualized fit
forCont4<-seq(from = min(myDat3.b$Cont4), to = max(myDat3.b$Cont4), by = 1)# a sequence of numbers in your numeric predictor range
  
# create a data frame with your predictors
forVis<-expand.grid(Cont4 = forCont4) # expand.grid() function makes sure you have all combinations of predictors.  

#### ii) using `predict()` to use your model to estimate your response variable at those values of your predictor


# Get your model fit estimates at each value of your predictors
modFit<-predict(bestMod3.b, # the model
                newdata = forVis, # the predictor values
                type = "link", # here, make the predictions on the link scale and we'll translate the back below
                se.fit = TRUE) # include uncertainty estimate

ilink <- family(bestMod3.b)$linkinv # get the conversion (inverse link) from the model to translate back to the response scale

forVis$Fit<-ilink(modFit$fit) # add your fit to the data frame
forVis$Upper<-ilink(modFit$fit + 1.96*modFit$se.fit) # add your uncertainty to the data frame, 95% confidence intervals
forVis$Lower<-ilink(modFit$fit - 1.96*modFit$se.fit) # add your uncertainty to the data frame


#### iii) use the model estimates to plot your model fit


library(ggplot2) # load ggplot2 library

ggplot() + # start ggplot
  
  geom_point(data = myDat3.b, # add observations to your plot
             mapping = aes(x = Cont4, y = Resp3.b)) + # control position of data points so they are easier to see on the plot
  
  geom_line(data = forVis, # add the modelled fit to your plot
              mapping = aes(x = Cont4, y = Fit),
              size = 1.2) + # control thickness of line
  
    geom_line(data = forVis, # add uncertainty to your plot (upper line)
              mapping = aes(x = Cont4, y = Upper),
              size = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
      geom_line(data = forVis, # add uncertainty to your plot (lower line)
              mapping = aes(x = Cont4, y = Lower),
              size = 0.8, # control thickness of line
              linetype = 2) + # control style of line
  
    geom_segment(aes(x=myInvPred, y=0.75, xend=myInvPred, yend=0), 
                 linewidth = 1.4, col="orange", 
                 arrow = arrow(length=unit(.3, 'cm'))) + # add line segment to plot
     
    geom_segment(aes(x=25, y=0.75, xend=unname(myInvPred)[1], yend=0.75), 
                 linewidth = 1.4,
                 col="orange") + # add line segment to plot
     
  scale_x_continuous(expand = c(0, 0), limits = c(25, NA))+
  
  ylab("probability Resp2.b = 1")+ # change y-axis label
  
  xlab("Cont4, (units)") + # change x-axis label
  
  theme_bw() # change ggplot theme



```




## Up next

You did it!  You made it through all the steps of our Statistical Modelling Framework.  Nice work!

Up next we will practice applying the framework to new examples, and learn how to [communicate](DSPPH_SM_Communicating) the whole process in reports and papers.





